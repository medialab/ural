import csv
from urllib.parse import urlsplit, parse_qsl
from collections import Counter
from tqdm import tqdm

from ural import normalize_url

TOP = 50

FRAGMENTS = Counter()
QUERIES = Counter()
QUERIES_COMBO = Counter()

with open("./scripts/data/urls.csv") as f:
    for line in tqdm(f, desc="Reading urls"):
        url = line.strip()[1:-1]
        url = normalize_url(url, strip_protocol=False)
        parsed = urlsplit(url)

        FRAGMENTS[parsed.fragment] += 1

        if parsed.query:
            for name, value in parse_qsl(parsed.query):
                QUERIES[name] += 1
                QUERIES_COMBO["%s=%s" % (name, value)] += 1


def report(name, counter):
    print()

    title = "Top %i %s:" % (TOP, name)
    print(title)
    print("-" * len(title))

    for record in counter.most_common(TOP):
        print("  â€¢ %s - %i" % record)

    print()


report("fragments", FRAGMENTS)
report("queries", QUERIES)
report("queries combo", QUERIES_COMBO)
